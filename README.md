# ğŸŒ Webscraping con sitio web

Este proyecto consiste en aplicar tÃ©cnicas de **webscraping** y **procesamiento de lenguaje natural (PLN)** para analizar un texto extraÃ­do de un sitio web donde una autora comparte su opiniÃ³n sobre el libro *PasiÃ³n* de Isabel Allende.  

## ğŸ“š LibrerÃ­as utilizadas

- `requests` â†’ realizar peticiones HTTP  
- `beautifulsoup4` â†’ parsear y navegar el HTML  
- `html5lib` â†’ parser tolerante a HTML desordenado  
- `re` â†’ expresiones regulares para limpieza de texto  
- `spacy` â†’ tokenizaciÃ³n, lematizaciÃ³n y stopwords en espaÃ±ol  
- `collections.Counter` â†’ conteo de frecuencias  
- `matplotlib` â†’ visualizaciÃ³n  
- `wordcloud` â†’ generar nubes de palabras  
- `scikit-learn` â†’ `CountVectorizer` y `TfidfVectorizer` para vectorizaciÃ³n  
- `numpy` â†’ manipulaciÃ³n de matrices

## ğŸ“ Pasos realizados

1. **Scraping**: descarga del HTML con `requests` y extracciÃ³n de pÃ¡rrafos con `BeautifulSoup`.  
2. **Limpieza inicial**: eliminaciÃ³n de caracteres raros, espacios extra y oraciones vacÃ­as.  
3. **Procesamiento lingÃ¼Ã­stico** con `spaCy`:  
   - TokenizaciÃ³n  
   - LematizaciÃ³n  
   - EliminaciÃ³n de *stopwords*  
   - Filtro de palabras cortas  
4. **ConstrucciÃ³n de oraciones limpias**: cada oraciÃ³n = un documento.  
5. **VectorizaciÃ³n**:  
   - **CountVectorizer** â†’ matriz documentoâ€“tÃ©rmino con frecuencias.  
   - **TfidfVectorizer** â†’ matriz con pesos TF-IDF que resaltan tÃ©rminos mÃ¡s relevantes.  
6. **VisualizaciÃ³n**: nube de palabras y anÃ¡lisis de frecuencias.  

---

## ğŸ¯ Objetivos

- Comprender cÃ³mo realizar **webscraping** para obtener texto desde un sitio web.  
- Aprender a **preprocesar texto** (limpieza, tokenizaciÃ³n, lematizaciÃ³n).  
- Generar una **representaciÃ³n numÃ©rica del texto** (matriz documentoâ€“vocabulario).  
- Analizar la **importancia de las palabras** con TF-IDF.  
- Visualizar resultados con una **nube de palabras**.  

---

## âœ… Â¿QuÃ© se logrÃ³?

- Se obtuvo un **texto limpio y normalizado** listo para anÃ¡lisis.  
- Se construyeron las matrices de **frecuencias** y **TF-IDF**.  
- Se identificaron los **tÃ©rminos mÃ¡s relevantes** del corpus.  
- Se comprendiÃ³ el flujo completo: *scraping â†’ limpieza â†’ preprocesamiento â†’ vectorizaciÃ³n â†’ visualizaciÃ³n*.  

---

âœ¨ Este trabajo muestra cÃ³mo pasar de un **texto en bruto de una web** a **datos numÃ©ricos listos para minerÃ­a de texto**.
